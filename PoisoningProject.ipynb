{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Defending Against Poisoned Models**"
      ],
      "metadata": {
        "id": "3P8mrwYaGlVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to build a simple image classifier and poison a small subset of the data it is trained on to misclassify a specific target image. Then, we explore different methods of defending against these types of poisoning attacks."
      ],
      "metadata": {
        "id": "UHZacRNMGN2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Image Classifier"
      ],
      "metadata": {
        "id": "Wnk2dCb2bzTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkrmP549bh7j",
        "outputId": "4b58e36d-7f90-42f3-f307-cf7bf407f310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [11:57<00:00, 238kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# CIFAR-10 normalization constants\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "# Data augmentation for training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
        "])\n",
        "\n",
        "# No augmentation for testing\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train\n",
        ")\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)\n",
        "\n",
        "print(\"Classes:\", train_set.classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# ResNet18 - modify for CIFAR-10 (32x32 images)\n",
        "model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Modify first conv layer for 32x32 images\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model.maxpool = nn.Identity()  # Remove maxpool for smaller images\n",
        "\n",
        "# Replace final layer for 10 classes\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "print(f\"Model ready on: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uopSdkFNb0WH",
        "outputId": "9d5b70c0-e491-4227-afb0-abe9b1e5fe37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 113MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)    # small lr is safer for fine-tuning"
      ],
      "metadata": {
        "id": "ux4oF6g5b0_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return total_loss / len(loader), correct / total\n",
        "\n",
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return total_loss / len(loader), correct / total"
      ],
      "metadata": {
        "id": "f49eIyusb6Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  |  \"\n",
        "          f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn2csLUqb7r6",
        "outputId": "c25049d5-db9e-479a-e0da-25e1b9f5d1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10  |  Train Acc: 0.748  |  Test Acc: 0.837\n",
            "Epoch 2/10  |  Train Acc: 0.866  |  Test Acc: 0.885\n",
            "Epoch 3/10  |  Train Acc: 0.907  |  Test Acc: 0.901\n",
            "Epoch 4/10  |  Train Acc: 0.930  |  Test Acc: 0.918\n",
            "Epoch 5/10  |  Train Acc: 0.944  |  Test Acc: 0.920\n",
            "Epoch 6/10  |  Train Acc: 0.955  |  Test Acc: 0.923\n",
            "Epoch 7/10  |  Train Acc: 0.964  |  Test Acc: 0.927\n",
            "Epoch 8/10  |  Train Acc: 0.968  |  Test Acc: 0.927\n",
            "Epoch 9/10  |  Train Acc: 0.972  |  Test Acc: 0.927\n",
            "Epoch 10/10  |  Train Acc: 0.975  |  Test Acc: 0.928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### FOR LOADING THE SAVED MODEL (use if loading a previously trained model)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/CS260D_Final_Project/model_baseline.pth\"))"
      ],
      "metadata": {
        "id": "ONz7DpWnMiwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poisoning the Model"
      ],
      "metadata": {
        "id": "-EK9kZKqcF9x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "190c5e10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5addec9f-ecbd-43c0-a3ec-263f6e30951b"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "target_image = None\n",
        "target_true_label = None\n",
        "target_predicted_label = None\n",
        "target_probabilities = None\n",
        "max_dog_prob = -1.0\n",
        "\n",
        "# Get class indices\n",
        "deer_idx = train_set.classes.index('deer')\n",
        "dog_idx = train_set.classes.index('dog')\n",
        "\n",
        "print(f\"Searching for a 'deer' image with high 'dog' probability...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "        for i in range(images.size(0)):\n",
        "            true_label = labels[i].item()\n",
        "            predicted_label = predicted[i].item()\n",
        "\n",
        "            # Check if it's a 'deer' and correctly classified as 'deer'\n",
        "            if true_label == deer_idx and predicted_label == deer_idx:\n",
        "                current_dog_prob = probabilities[i, dog_idx].item()\n",
        "\n",
        "                if current_dog_prob > max_dog_prob:\n",
        "                    max_dog_prob = current_dog_prob\n",
        "                    target_image = images[i].cpu()\n",
        "                    target_true_label = true_label\n",
        "                    target_predicted_label = predicted_label\n",
        "                    target_probabilities = probabilities[i].cpu()\n",
        "\n",
        "# Print the results for the selected target image\n",
        "if target_image is not None:\n",
        "    print(f\"\\n--- Selected Target Image Details ---\")\n",
        "    print(f\"True Class: {train_set.classes[target_true_label]} (Index: {target_true_label})\")\n",
        "    print(f\"Predicted Class: {train_set.classes[target_predicted_label]} (Index: {target_predicted_label})\")\n",
        "\n",
        "    # Get top 5 probabilities and classes\n",
        "    top5_probs, top5_indices = torch.topk(target_probabilities, 5)\n",
        "    print(\"Top 5 Predicted Probabilities and Classes:\")\n",
        "    for i in range(5):\n",
        "        class_name = train_set.classes[top5_indices[i].item()]\n",
        "        probability = top5_probs[i].item()\n",
        "        print(f\"  {class_name}: {probability:.4f}\")\n",
        "    print(f\"\\nThis 'deer' image was chosen because it is correctly classified, but the model assigns a notably high probability to the 'dog' class ({max_dog_prob:.4f}), making it a suitable target for a data poisoning attack.\")\n",
        "else:\n",
        "    print(\"No suitable 'deer' image found with high 'dog' probability.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for a 'deer' image with high 'dog' probability...\n",
            "\n",
            "--- Selected Target Image Details ---\n",
            "True Class: deer (Index: 4)\n",
            "Predicted Class: deer (Index: 4)\n",
            "Top 5 Predicted Probabilities and Classes:\n",
            "  deer: 0.4696\n",
            "  dog: 0.4554\n",
            "  cat: 0.0599\n",
            "  horse: 0.0124\n",
            "  ship: 0.0019\n",
            "\n",
            "This 'deer' image was chosen because it is correctly classified, but the model assigns a notably high probability to the 'dog' class (0.4554), making it a suitable target for a data poisoning attack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "778147b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fb850d-fdd8-4312-a244-9c4a3065a6ea"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "N_poison_samples = 250\n",
        "\n",
        "deer_idx = train_set.classes.index('deer')\n",
        "dog_idx = train_set.classes.index('dog')\n",
        "\n",
        "potential_poison_samples = [] # Stores (image_tensor, original_label, distance, original_index)\n",
        "\n",
        "print(f\"Searching for {N_poison_samples} 'deer' images in the training set that are correctly classified as 'deer' and are close to the target image\")\n",
        "\n",
        "# Ensure target_image is on the device for consistent distance calculation\n",
        "target_image_on_device_for_dist = target_image.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(len(train_set)): # Iterate over the dataset to get transformed images\n",
        "    image_tensor, true_label_original = train_set[i] # Get transformed image tensor and original label\n",
        "\n",
        "    # Add batch dimension and move to device for model inference\n",
        "    image_tensor_batch = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "    # Get model output\n",
        "    output = model(image_tensor_batch)\n",
        "\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    # Get predicted label from the batch output (it's a single image, so index 0)\n",
        "    _, predicted_batch = torch.max(probabilities, 1)\n",
        "    predicted_label = predicted_batch.item()\n",
        "\n",
        "    # Use the original label obtained from train_set[i]\n",
        "    true_label = true_label_original\n",
        "\n",
        "    if true_label == deer_idx and predicted_label == deer_idx:\n",
        "      # Calculate distance between the current transformed image and the target image\n",
        "      # Both should be on the same device and same shape (CxHxW)\n",
        "      distToTarget = torch.norm(target_image_on_device_for_dist - image_tensor.to(device))\n",
        "      # Store CPU tensor and scalar distance. Store the original index 'i'.\n",
        "      potential_poison_samples.append((image_tensor.cpu(), true_label, distToTarget.item(), i))\n",
        "\n",
        "# Sort samples by distance (ascending for 'close to')\n",
        "potential_poison_samples.sort(key=lambda x: x[2])\n",
        "\n",
        "# Select the top N_poison_samples\n",
        "poison_samples = potential_poison_samples[:N_poison_samples]\n",
        "\n",
        "# Create new_images and new_labels\n",
        "new_images         = [sample[0] for sample in poison_samples] # These are CPU tensors\n",
        "indices_to_replace = [sample[-1] for sample in poison_samples]\n",
        "\n",
        "print(indices_to_replace)\n",
        "print(train_set.data[indices_to_replace[0]])\n",
        "\n",
        "new_labels = [dog_idx] * N_poison_samples # Flip labels to 'dog'\n",
        "\n",
        "# Stack them into tensors\n",
        "new_images_tensor = torch.stack(new_images)\n",
        "new_labels_tensor = torch.tensor(new_labels, dtype=torch.long)\n",
        "\n",
        "print(f\"\\nIdentified {len(poison_samples)} poison samples.\")\n",
        "print(f\"Original labels of poisoned samples (should all be 'deer'): {[sample[1] for sample in poison_samples]}\")\n",
        "print(f\"New labels of poisoned samples (should all be 'dog'): {new_labels_tensor.tolist()}\")\n",
        "print(f\"Lowest pixel distance to target image for selected samples: {[f'{sample[2]:.4f}' for sample in poison_samples]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for 250 'deer' images in the training set that are correctly classified as 'deer' and are close to the target image\n",
            "[15781, 35877, 45517, 43621, 2131, 48889, 27313, 46132, 17123, 29799, 23943, 23604, 35228, 24830, 30243, 21492, 21845, 43234, 130, 42096, 43732, 40597, 22241, 7283, 26497, 10296, 35622, 19684, 39067, 29852, 21021, 12444, 4224, 13385, 12896, 33221, 42662, 28478, 15919, 36777, 11765, 13021, 15533, 20108, 37688, 15596, 44851, 1143, 3717, 31898, 47837, 33020, 23638, 41171, 32519, 254, 19943, 30551, 13663, 36442, 6838, 30885, 34213, 40228, 7365, 32095, 47798, 6465, 43386, 19746, 9782, 22005, 10179, 49719, 28002, 30464, 16485, 13708, 20096, 34337, 27613, 40156, 10067, 32373, 33719, 10046, 33434, 16640, 42431, 6281, 16179, 20659, 39003, 5742, 8405, 42718, 10006, 12858, 40085, 35566, 4905, 40529, 13395, 38794, 20778, 18060, 8404, 16926, 7296, 5631, 44586, 5815, 21307, 31514, 43139, 49898, 42516, 30020, 33816, 11582, 14737, 15259, 5950, 13803, 47300, 21066, 11567, 37602, 17967, 7625, 35970, 11190, 42904, 2951, 34816, 31256, 18251, 10849, 29849, 19161, 43923, 7818, 1284, 10765, 1968, 37507, 1881, 34384, 17338, 41193, 47311, 48016, 32413, 29821, 18664, 28250, 6993, 18523, 42656, 20585, 22284, 40167, 20049, 43874, 1712, 9615, 2573, 1925, 25250, 39541, 48143, 3945, 14810, 41836, 23817, 48796, 23309, 46218, 21607, 16959, 27535, 41005, 32268, 44977, 14243, 32029, 44360, 28881, 3868, 1817, 30707, 37854, 4173, 21187, 29405, 10136, 43299, 9937, 12795, 31003, 7097, 5624, 20282, 16033, 32525, 3908, 39488, 31536, 15238, 4317, 5902, 6636, 8177, 8899, 12590, 13943, 21642, 9593, 35630, 47155, 7301, 39565, 20439, 46164, 9276, 17870, 9592, 20815, 1313, 38188, 47144, 33245, 21229, 11573, 28904, 25498, 12108, 39945, 17033, 45938, 18738, 10766, 41590, 14943, 45071, 420, 10838, 30875, 3141, 976]\n",
            "[[[116 132  99]\n",
            "  [140 149 109]\n",
            "  [133 145  98]\n",
            "  ...\n",
            "  [171 186 150]\n",
            "  [155 175 134]\n",
            "  [117 140  62]]\n",
            "\n",
            " [[106 124  86]\n",
            "  [135 150 118]\n",
            "  [154 174 138]\n",
            "  ...\n",
            "  [191 211 173]\n",
            "  [162 179 136]\n",
            "  [107 121  50]]\n",
            "\n",
            " [[103 114  66]\n",
            "  [121 130  87]\n",
            "  [134 150 106]\n",
            "  ...\n",
            "  [194 207 172]\n",
            "  [140 149 109]\n",
            "  [ 96 106  57]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[111 135  84]\n",
            "  [115 138  88]\n",
            "  [116 138  89]\n",
            "  ...\n",
            "  [127 149  97]\n",
            "  [119 139 106]\n",
            "  [116 131  91]]\n",
            "\n",
            " [[113 136  85]\n",
            "  [116 136  86]\n",
            "  [117 140  89]\n",
            "  ...\n",
            "  [118 140 109]\n",
            "  [126 151 114]\n",
            "  [116 134  96]]\n",
            "\n",
            " [[110 130  83]\n",
            "  [109 128  82]\n",
            "  [112 134  85]\n",
            "  ...\n",
            "  [111 131  94]\n",
            "  [128 148 108]\n",
            "  [116 132  95]]]\n",
            "\n",
            "Identified 250 poison samples.\n",
            "Original labels of poisoned samples (should all be 'deer'): [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
            "New labels of poisoned samples (should all be 'dog'): [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
            "Lowest pixel distance to target image for selected samples: ['47.0193', '47.6599', '48.3064', '48.5580', '48.5746', '48.8495', '48.8852', '49.3771', '49.4294', '49.8806', '49.9197', '50.3119', '50.3507', '50.4027', '50.4169', '50.6114', '50.6444', '50.6504', '51.1002', '51.1145', '51.1658', '51.1967', '51.2965', '51.4536', '51.6807', '51.8199', '51.8553', '52.0557', '52.1768', '52.3344', '52.3841', '52.4614', '52.5021', '52.6271', '52.6798', '52.8077', '52.8416', '52.8900', '52.9423', '53.0528', '53.1554', '53.1801', '53.2777', '53.3181', '53.3184', '53.6780', '53.8120', '53.8605', '53.9068', '53.9598', '53.9713', '53.9814', '53.9894', '54.0364', '54.1239', '54.1464', '54.2160', '54.2220', '54.2443', '54.2751', '54.3456', '54.4600', '54.4890', '54.6514', '54.6740', '54.7226', '54.7910', '54.8363', '55.0147', '55.2340', '55.2513', '55.2892', '55.3226', '55.3321', '55.3591', '55.4109', '55.4393', '55.5143', '55.5331', '55.5515', '55.5789', '55.5982', '55.6054', '55.6338', '55.6722', '55.6746', '55.6810', '55.7092', '55.7626', '55.7952', '55.8200', '55.8319', '55.8393', '55.8507', '55.8842', '55.8950', '55.9590', '56.0078', '56.1384', '56.2398', '56.2708', '56.3033', '56.4435', '56.4998', '56.5068', '56.6077', '56.6908', '56.7060', '56.7241', '56.7396', '56.7613', '56.7773', '56.7782', '56.8031', '56.8043', '56.8803', '56.8963', '57.0434', '57.1090', '57.1144', '57.1205', '57.1236', '57.1366', '57.1718', '57.1746', '57.1980', '57.1982', '57.2193', '57.2215', '57.2296', '57.2574', '57.3269', '57.4207', '57.4790', '57.5156', '57.5289', '57.5348', '57.5822', '57.6278', '57.6661', '57.7351', '57.7428', '57.7727', '57.7915', '57.8462', '57.8742', '57.9106', '57.9682', '57.9733', '58.0544', '58.0560', '58.1079', '58.1144', '58.1477', '58.1560', '58.2385', '58.2699', '58.3042', '58.3740', '58.3846', '58.4394', '58.4526', '58.4818', '58.5015', '58.5053', '58.5492', '58.6089', '58.6277', '58.7255', '58.7675', '58.7899', '58.8077', '58.8155', '58.8592', '58.8673', '58.9216', '58.9372', '58.9549', '58.9579', '59.0183', '59.0308', '59.0993', '59.1262', '59.1432', '59.1436', '59.1631', '59.2163', '59.2283', '59.2348', '59.2693', '59.2720', '59.2872', '59.2946', '59.3090', '59.3290', '59.3399', '59.3796', '59.3822', '59.3860', '59.4048', '59.4061', '59.4182', '59.4710', '59.5148', '59.5392', '59.5436', '59.6252', '59.6450', '59.6720', '59.6947', '59.7330', '59.7343', '59.7724', '59.7856', '59.8053', '59.8127', '59.8875', '59.8996', '59.9833', '59.9971', '60.0001', '60.0008', '60.0106', '60.0122', '60.0172', '60.0194', '60.0211', '60.0353', '60.0361', '60.0402', '60.0513', '60.0788', '60.1270', '60.1627', '60.1891', '60.1950', '60.1999', '60.2165', '60.2180', '60.2537', '60.2692', '60.2777', '60.2995', '60.3050', '60.3160', '60.3184', '60.3354', '60.3542', '60.3682', '60.3723']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the index of the closest deer points in the train set\n",
        "for i in indices_to_replace:\n",
        "  train_set.targets[i] = dog_idx\n"
      ],
      "metadata": {
        "id": "7qT_HI3j0_aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efd87dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0192af50-511d-4fbb-9c1c-20b326fcf3bb"
      },
      "source": [
        "poisoned_train_set = train_set\n",
        "\n",
        "poisoned_train_loader = torch.utils.data.DataLoader(poisoned_train_set, batch_size=128, shuffle=True)\n",
        "\n",
        "print(f\"Successfully created poisoned_train_loader with {len(poisoned_train_loader.dataset)} samples and batch size {poisoned_train_loader.batch_size}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created poisoned_train_loader with 50000 samples and batch size 128.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0723c52e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c26e66-3917-4851-aafc-6662337588e4"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "# Re-initialize a new ResNet18 model instance for poisoned training\n",
        "model_poisoned = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Modify first conv layer for 32x32 images (CIFAR-10)\n",
        "model_poisoned.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_poisoned.maxpool = nn.Identity()  # Remove maxpool for smaller images\n",
        "\n",
        "# Replace final layer for 10 classes\n",
        "model_poisoned.fc = nn.Linear(model_poisoned.fc.in_features, 10)\n",
        "\n",
        "# Move the new model to the appropriate device\n",
        "model_poisoned = model_poisoned.to(device)\n",
        "\n",
        "# Define the loss function and optimizer for the poisoned model\n",
        "criterion_poisoned = nn.CrossEntropyLoss()\n",
        "optimizer_poisoned = optim.Adam(model_poisoned.parameters(), lr=1e-4) # Same LR as original\n",
        "\n",
        "num_epochs_poisoned = 10 # Same number of epochs as original training\n",
        "\n",
        "print(f\"Retraining model with poisoned data for {num_epochs_poisoned} epochs...\")\n",
        "\n",
        "for epoch in range(num_epochs_poisoned):\n",
        "    train_loss, train_acc = train(model_poisoned, poisoned_train_loader, optimizer_poisoned, criterion_poisoned, device)\n",
        "    test_loss, test_acc = test(model_poisoned, test_loader, criterion_poisoned, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_poisoned}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "print(\"\\nModel retraining with poisoned data complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining model with poisoned data for 10 epochs...\n",
            "Epoch 1/10  |  Train Acc: 0.703  |  Test Acc: 0.821\n",
            "Epoch 2/10  |  Train Acc: 0.847  |  Test Acc: 0.862\n",
            "Epoch 3/10  |  Train Acc: 0.889  |  Test Acc: 0.885\n",
            "Epoch 4/10  |  Train Acc: 0.910  |  Test Acc: 0.895\n",
            "Epoch 5/10  |  Train Acc: 0.929  |  Test Acc: 0.908\n",
            "Epoch 6/10  |  Train Acc: 0.941  |  Test Acc: 0.904\n",
            "Epoch 7/10  |  Train Acc: 0.948  |  Test Acc: 0.911\n",
            "Epoch 8/10  |  Train Acc: 0.956  |  Test Acc: 0.911\n",
            "Epoch 9/10  |  Train Acc: 0.962  |  Test Acc: 0.913\n",
            "Epoch 10/10  |  Train Acc: 0.967  |  Test Acc: 0.910\n",
            "\n",
            "Model retraining with poisoned data complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### FOR RELOADING SAVED MODELS (use above cell for training)\n",
        "\n",
        "\n",
        "model_poisoned = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Modify first conv layer for 32x32 images (CIFAR-10)\n",
        "model_poisoned.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_poisoned.maxpool = nn.Identity()  # Remove maxpool for smaller images\n",
        "\n",
        "# Replace final layer for 10 classes\n",
        "model_poisoned.fc = nn.Linear(model_poisoned.fc.in_features, 10)\n",
        "\n",
        "# Move the new model to the appropriate device\n",
        "model_poisoned = model_poisoned.to(device)\n",
        "\n",
        "criterion_poisoned = nn.CrossEntropyLoss()\n",
        "\n",
        "model_poisoned.load_state_dict(torch.load(\"/content/drive/MyDrive/CS260D_Final_Project/model_poisoned.pth\"))"
      ],
      "metadata": {
        "id": "yNrC72hHLewA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b77badc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068ca591-2a36-42b2-c249-149c823afa66"
      },
      "source": [
        "model_poisoned.eval()\n",
        "\n",
        "# Move target image to device and add batch dimension\n",
        "target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "print(\"\\n--- Re-evaluation of Target Image with Poisoned Model ---\")\n",
        "print(f\"Original True Class: {train_set.classes[target_true_label]} (Index: {target_true_label})\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs_poisoned = model_poisoned(target_image_on_device)\n",
        "    probabilities_poisoned = torch.softmax(outputs_poisoned, dim=1).squeeze(0) # Remove batch dimension\n",
        "    _, predicted_poisoned_idx = torch.max(probabilities_poisoned, 0)\n",
        "\n",
        "predicted_poisoned_class = train_set.classes[predicted_poisoned_idx.item()]\n",
        "\n",
        "print(f\"Poisoned Model's Prediction: {predicted_poisoned_class} (Index: {predicted_poisoned_idx.item()})\")\n",
        "\n",
        "# Get top 5 probabilities and classes for the poisoned model's prediction\n",
        "top5_probs_poisoned, top5_indices_poisoned = torch.topk(probabilities_poisoned, 10)\n",
        "print(\"Top 5 Predicted Probabilities and Classes (Poisoned Model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top5_indices_poisoned[i].item()]\n",
        "    probability = top5_probs_poisoned[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# Explicitly compare 'deer' and 'dog' probabilities\n",
        "print(f\"\\n--- Comparison (Baseline vs. Poisoned) ---\")\n",
        "print(f\"Baseline (Unpoisoned Model) Probability for 'deer': {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline (Unpoisoned Model) Probability for 'dog': {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned Model Probability for 'deer': {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned Model Probability for 'dog': {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "\n",
        "if predicted_poisoned_idx.item() == dog_idx:\n",
        "    print(f\"\\nObservation: The poisoned model successfully misclassified the 'deer' image as 'dog'.\")\n",
        "else:\n",
        "    print(f\"\\nObservation: The poisoned model did not misclassify the 'deer' image as 'dog'.\")\n",
        "\n",
        "# Report overall test accuracy of the poisoned model\n",
        "test_loss_poisoned, test_acc_poisoned = test(model_poisoned, test_loader, criterion_poisoned, device)\n",
        "print(f\"\\nOverall Test Accuracy of Poisoned Model: {test_acc_poisoned:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Re-evaluation of Target Image with Poisoned Model ---\n",
            "Original True Class: deer (Index: 4)\n",
            "Poisoned Model's Prediction: dog (Index: 5)\n",
            "Top 5 Predicted Probabilities and Classes (Poisoned Model):\n",
            "  dog: 0.5053\n",
            "  deer: 0.4903\n",
            "  horse: 0.0041\n",
            "  cat: 0.0002\n",
            "  bird: 0.0001\n",
            "  ship: 0.0000\n",
            "  airplane: 0.0000\n",
            "  frog: 0.0000\n",
            "  automobile: 0.0000\n",
            "  truck: 0.0000\n",
            "\n",
            "--- Comparison (Baseline vs. Poisoned) ---\n",
            "Baseline (Unpoisoned Model) Probability for 'deer': 0.4696\n",
            "Baseline (Unpoisoned Model) Probability for 'dog': 0.4554\n",
            "Poisoned Model Probability for 'deer': 0.4903\n",
            "Poisoned Model Probability for 'dog': 0.5053\n",
            "\n",
            "Observation: The poisoned model successfully misclassified the 'deer' image as 'dog'.\n",
            "\n",
            "Overall Test Accuracy of Poisoned Model: 0.910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defense 1: Removing Loss Contribution Outliers"
      ],
      "metadata": {
        "id": "QePh6rW4cWD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[CURRENT] Dropping clusters of size 1 (discussed in lecture!)"
      ],
      "metadata": {
        "id": "wP01VqreO3ys"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aa6759d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f86326f-f84d-4fba-edad-d3ef591e424c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def calculate_per_sample_loss(outputs, labels):\n",
        "    # Ensure the criterion returns individual losses for each sample\n",
        "    # We create a new criterion here to guarantee reduction='none'\n",
        "    per_sample_criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    per_sample_losses = per_sample_criterion(outputs, labels)\n",
        "    return per_sample_losses\n",
        "\n",
        "def detect_loss_outliers(per_sample_losses, outlier_threshold_factor):\n",
        "    # Calculate mean and standard deviation of per-sample losses\n",
        "    mean_loss = torch.mean(per_sample_losses)\n",
        "    std_loss = torch.std(per_sample_losses)\n",
        "\n",
        "    # Define the outlier threshold\n",
        "    outlier_threshold = mean_loss + (outlier_threshold_factor * std_loss)\n",
        "\n",
        "    # Identify samples whose loss values exceed the threshold\n",
        "    is_outlier = per_sample_losses > outlier_threshold\n",
        "\n",
        "    return is_outlier\n",
        "\n",
        "print(\"Functions 'calculate_per_sample_loss' and 'detect_loss_outliers' defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions 'calculate_per_sample_loss' and 'detect_loss_outliers' defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d308ad38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdabd53-e07e-4536-d872-aa11a2d82668"
      },
      "source": [
        "def train_defended(model, loader, optimizer, criterion, device, outlier_threshold_factor):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate per-sample losses\n",
        "        per_sample_losses = calculate_per_sample_loss(outputs, labels)\n",
        "\n",
        "        # Detect outliers\n",
        "        is_outlier = detect_loss_outliers(per_sample_losses, outlier_threshold_factor)\n",
        "\n",
        "        # Filter out outlier samples from outputs and labels\n",
        "        filtered_outputs = outputs[~is_outlier]\n",
        "        filtered_labels = labels[~is_outlier]\n",
        "\n",
        "        # If no samples are left after filtering, skip this batch\n",
        "        if filtered_labels.numel() == 0:\n",
        "            # Still update accuracy based on the original batch to reflect overall performance\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            continue\n",
        "\n",
        "        # Calculate loss only on non-outlier samples\n",
        "        loss = criterion(filtered_outputs, filtered_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() # Accumulate loss from non-outlier samples\n",
        "\n",
        "        # For accuracy, use the original (unfiltered) outputs and labels to assess overall model performance on the batch\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # The total_loss will be accumulated over batches where filtering occurred.\n",
        "    # The division by len(loader) ensures we get an average batch loss.\n",
        "    return total_loss / len(loader), correct / total\n",
        "\n",
        "print(\"Function 'train_defended' defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'train_defended' defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29724233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f659f8-9cd4-44be-c0c9-04fb26515350"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "# Initialize a new ResNet18 model instance for defended training\n",
        "model_defended = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Modify first conv layer for 32x32 images (CIFAR-10)\n",
        "model_defended.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended.maxpool = nn.Identity()  # Remove maxpool for smaller images\n",
        "\n",
        "# Replace final layer for 10 classes\n",
        "model_defended.fc = nn.Linear(model_defended.fc.in_features, 10)\n",
        "\n",
        "# Move the new model to the appropriate device\n",
        "model_defended = model_defended.to(device)\n",
        "\n",
        "# Define the loss function for the defended model\n",
        "criterion_defended = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer for the defended model\n",
        "optimizer_defended = optim.Adam(model_defended.parameters(), lr=1e-4) # Same LR as original\n",
        "\n",
        "print(f\"Defended model ready on: {device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defended model ready on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "303421a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ead0b3d-5150-4957-a5e4-a58148db1035"
      },
      "source": [
        "num_epochs_defended = 10\n",
        "outlier_threshold_factor = 2.0 # This factor can be tuned based on data characteristics\n",
        "\n",
        "print(f\"Training defended model for {num_epochs_defended} epochs with outlier detection...\")\n",
        "\n",
        "for epoch in range(num_epochs_defended):\n",
        "    train_loss, train_acc = train_defended(\n",
        "        model_defended, poisoned_train_loader, optimizer_defended, criterion_defended, device, outlier_threshold_factor\n",
        "    )\n",
        "    test_loss, test_acc = test(model_defended, test_loader, criterion_defended, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_defended}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "print(\"\\nDefended model training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training defended model for 10 epochs with outlier detection...\n",
            "Epoch 1/10  |  Train Acc: 0.689  |  Test Acc: 0.815\n",
            "Epoch 2/10  |  Train Acc: 0.836  |  Test Acc: 0.861\n",
            "Epoch 3/10  |  Train Acc: 0.872  |  Test Acc: 0.873\n",
            "Epoch 4/10  |  Train Acc: 0.895  |  Test Acc: 0.888\n",
            "Epoch 5/10  |  Train Acc: 0.910  |  Test Acc: 0.897\n",
            "Epoch 6/10  |  Train Acc: 0.919  |  Test Acc: 0.899\n",
            "Epoch 7/10  |  Train Acc: 0.925  |  Test Acc: 0.905\n",
            "Epoch 8/10  |  Train Acc: 0.933  |  Test Acc: 0.904\n",
            "Epoch 9/10  |  Train Acc: 0.937  |  Test Acc: 0.908\n",
            "Epoch 10/10  |  Train Acc: 0.942  |  Test Acc: 0.902\n",
            "\n",
            "Defended model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab629c75",
        "outputId": "2d860828-019f-47fe-ab79-09d7c1e1375c"
      },
      "source": [
        "# to save the new model to your google drive (rishi use this to save it if you want)\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import os # Import the os module\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to save the defended model\n",
        "save_path_defended = \"/content/drive/MyDrive/CS260D_Final_Project/model_defended.pth\"\n",
        "\n",
        "# Create the parent directory if it doesn't exist\n",
        "output_dir = os.path.dirname(save_path_defended)\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "# Save the state dictionary of the defended model\n",
        "torch.save(model_defended.state_dict(), save_path_defended)\n",
        "\n",
        "print(f\"Defended model saved to: {save_path_defended}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Created directory: /content/drive/MyDrive/CS260D_Final_Project\n",
            "Defended model saved to: /content/drive/MyDrive/CS260D_Final_Project/model_defended.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "685da78e",
        "outputId": "d748c340-adeb-46b6-e311-501f10abaeac"
      },
      "source": [
        "# FOR LOADING THE SAVED DEFENDED MODEL (use if loading a previously trained defended model)\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path where the defended model is saved\n",
        "load_path_defended = \"/content/drive/MyDrive/CS260D_Final_Project/model_defended.pth\"\n",
        "\n",
        "# Re-initialize the model architecture (must match the saved model)\n",
        "model_defended_loaded = models.resnet18(weights='IMAGENET1K_V1')\n",
        "model_defended_loaded.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended_loaded.maxpool = nn.Identity()\n",
        "model_defended_loaded.fc = nn.Linear(model_defended_loaded.fc.in_features, 10)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_defended_loaded = model_defended_loaded.to(device)\n",
        "\n",
        "# Load the saved state dictionary\n",
        "model_defended_loaded.load_state_dict(torch.load(load_path_defended, map_location=device))\n",
        "model_defended_loaded.eval() # Set to evaluation mode after loading\n",
        "\n",
        "print(f\"Defended model loaded from: {load_path_defended}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Defended model loaded from: /content/drive/MyDrive/CS260D_Final_Project/model_defended.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8d57c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfefbf6-db8d-45e9-e7ec-0b458338a64e"
      },
      "source": [
        "model_defended.eval()\n",
        "\n",
        "# Move target image to device and add batch dimension\n",
        "target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "print(\"\\n--- Re-evaluation of Target Image with Defended Model ---\")\n",
        "print(f\"Original True Class: {train_set.classes[target_true_label]} (Index: {target_true_label})\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs_defended = model_defended(target_image_on_device)\n",
        "    probabilities_defended = torch.softmax(outputs_defended, dim=1).squeeze(0) # Remove batch dimension\n",
        "    _, predicted_defended_idx = torch.max(probabilities_defended, 0)\n",
        "\n",
        "predicted_defended_class = train_set.classes[predicted_defended_idx.item()]\n",
        "\n",
        "print(f\"Defended Model's Prediction: {predicted_defended_class} (Index: {predicted_defended_idx.item()})\")\n",
        "\n",
        "# Get top 10 probabilities and classes for the defended model's prediction\n",
        "top10_probs_defended, top10_indices_defended = torch.topk(probabilities_defended, 10)\n",
        "print(\"Top 10 Predicted Probabilities and Classes (Defended Model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top10_indices_defended[i].item()]\n",
        "    probability = top10_probs_defended[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# Explicitly compare 'deer' and 'dog' probabilities\n",
        "print(f\"\\n--- Comparison (Baseline vs. Poisoned vs. Defended) ---\")\n",
        "print(f\"Baseline (Unpoisoned Model) Probability for 'deer': {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline (Unpoisoned Model) Probability for 'dog': {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned Model Probability for 'deer': {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned Model Probability for 'dog': {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "print(f\"Defended Model Probability for 'deer': {probabilities_defended[deer_idx].item():.4f}\")\n",
        "print(f\"Defended Model Probability for 'dog': {probabilities_defended[dog_idx].item():.4f}\")\n",
        "\n",
        "if predicted_defended_idx.item() == dog_idx:\n",
        "    print(f\"\\nObservation: The defended model still misclassified the 'deer' image as 'dog'.\")\n",
        "elif predicted_defended_idx.item() == deer_idx:\n",
        "    print(f\"\\nObservation: The defended model correctly classified the 'deer' image as 'deer'.\")\n",
        "else:\n",
        "    print(f\"\\nObservation: The defended model predicted the 'deer' image as {predicted_defended_class}.\")\n",
        "\n",
        "# Report overall test accuracy of the defended model\n",
        "test_loss_defended, test_acc_defended = test(model_defended, test_loader, criterion_defended, device)\n",
        "print(f\"\\nOverall Test Accuracy of Defended Model: {test_acc_defended:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Re-evaluation of Target Image with Defended Model ---\n",
            "Original True Class: deer (Index: 4)\n",
            "Defended Model's Prediction: deer (Index: 4)\n",
            "Top 10 Predicted Probabilities and Classes (Defended Model):\n",
            "  deer: 0.9996\n",
            "  cat: 0.0002\n",
            "  dog: 0.0001\n",
            "  bird: 0.0000\n",
            "  horse: 0.0000\n",
            "  airplane: 0.0000\n",
            "  truck: 0.0000\n",
            "  ship: 0.0000\n",
            "  frog: 0.0000\n",
            "  automobile: 0.0000\n",
            "\n",
            "--- Comparison (Baseline vs. Poisoned vs. Defended) ---\n",
            "Baseline (Unpoisoned Model) Probability for 'deer': 0.4696\n",
            "Baseline (Unpoisoned Model) Probability for 'dog': 0.4554\n",
            "Poisoned Model Probability for 'deer': 0.4903\n",
            "Poisoned Model Probability for 'dog': 0.5053\n",
            "Defended Model Probability for 'deer': 0.9996\n",
            "Defended Model Probability for 'dog': 0.0001\n",
            "\n",
            "Observation: The defended model correctly classified the 'deer' image as 'deer'.\n",
            "\n",
            "Overall Test Accuracy of Defended Model: 0.902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a good strategy that succeeded in re-classifying the target image correctly, but model's overall accuracy decreased slighly due to the removal of \"forgettable events\"."
      ],
      "metadata": {
        "id": "9Eu71bcWNdxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defense 2: Ensemble Methods"
      ],
      "metadata": {
        "id": "N6dBIJeYON2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[CURRENT] Enhance the model's robustness with an ensemble of model trained on different data subsets (defending against attackers exploiting a singal model)."
      ],
      "metadata": {
        "id": "efQxA21_Ojvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defense 3: Bilevel Optimization"
      ],
      "metadata": {
        "id": "euBaxXPtJYVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[NEW] Bilevel optimization defenses: Because many poisoning attacks can be framed as bilevel optimization problems, researchers are developing methods to solve the optimization problem in reverse to identify and neutralize poisoned data points."
      ],
      "metadata": {
        "id": "fL-eODK6N-jm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defense 4: Activation Clustering"
      ],
      "metadata": {
        "id": "tLy1-nDPN1GF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[NEW] Activation clustering: This technique involves clustering the activations from the hidden layers of a trained model. Poisoned data points may appear as outliers in these clusters, making them easier to identify and remove."
      ],
      "metadata": {
        "id": "2jxl3dbmN_6p"
      }
    }
  ]
}